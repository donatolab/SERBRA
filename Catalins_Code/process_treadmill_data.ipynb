{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.set_autosave_interval(180000)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-e54c02c9d18a>:13: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "#matplotlib.use('qtagg')\n",
    "%matplotlib tk\n",
    "%autosave 180\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import nest_asyncio\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that loads the original datasets\n",
    "def reload_names():\n",
    "\n",
    "    # hard coded names for each session x 3 recordings\n",
    "    fname_tracks = [\n",
    "\n",
    "        ['/media/cat/4TB/donato/steffen/DON-004366/20210228/suite2p/plane0/mat/DON-004366_20210228_TRD-2P_S1-ACQ_eval.mat',\n",
    "         '/media/cat/4TB/donato/steffen/DON-004366/20210228/suite2p/plane0/mat/DON-004366_20210228_TRD-2P_S2-ACQ_eval.mat',\n",
    "         '/media/cat/4TB/donato/steffen/DON-004366/20210228/suite2p/plane0/mat/DON-004366_20210228_TRD-2P_S3-ACQ_eval.mat'],\n",
    "\n",
    "         # \n",
    "         ['/media/cat/4TB/donato/steffen/DON-004366/20210301/mat/DON-004366_20210301_TRD-2P_S1-ACQ_eval.mat',\n",
    "         '/media/cat/4TB/donato/steffen/DON-004366/20210301/mat/DON-004366_20210301_TRD-2P_S2-ACQ_eval.mat',\n",
    "         '/media/cat/4TB/donato/steffen/DON-004366/20210301/mat/DON-004366_20210301_TRD-2P_S3-ACQ_eval.mat'],\n",
    "\n",
    "        # \n",
    "        ['/media/cat/4TB/donato/steffen/DON-004366/20210303/DON-004366_20210303_TRD-2P_S1-ACQ_eval.mat',\n",
    "        '/media/cat/4TB/donato/steffen/DON-004366/20210303/DON-004366_20210303_TRD-2P_S2-ACQ_eval.mat',\n",
    "        '/media/cat/4TB/donato/steffen/DON-004366/20210303/DON-004366_20210303_TRD-2P_S3-ACQ_eval.mat'\n",
    "    ]\n",
    "\n",
    "    # \n",
    "    fnames_ca = [\n",
    "        '/media/cat/4TB/donato/steffen/DON-004366/20210228/suite2p/plane0/binarized_traces/F_upphase.npy',\n",
    "        '/media/cat/4TB/donato/steffen/DON-004366/20210301/binarized_traces/F_upphase.npy',\n",
    "        '/media/cat/4TB/donato/steffen/DON-004366/20210303/binarized_traces/F_upphase.npy']\n",
    "\n",
    "    # segmaentaiton: \n",
    "    segment_order = [\n",
    "                    [\"A\", \"B\", \"A'\"],\n",
    "                    [\"A\", \"A'\",\"B\"],\n",
    "                    [\"A\", \"B\", \"A'\"]       \n",
    "                    ]\n",
    "    \n",
    "    return fname_tracks, fnames_ca, segment_order\n",
    "\n",
    "#\n",
    "def load_tracks(fname_tracks, bin_width=5):\n",
    "\n",
    "    #\n",
    "    pos_tracks = []\n",
    "    idx_tracks = []\n",
    "    idx_ctr = 0\n",
    "    for fname_track in fname_tracks:\n",
    "        with h5py.File(fname_track, 'r') as file:\n",
    "            #\n",
    "            pos = file['trdEval']['position_atframe'][()].squeeze()\n",
    "\n",
    "            n_timesteps = pos.shape[0]\n",
    "            #print (\"# of time steps: \", pos.shape)\n",
    "\n",
    "        # bin speed for some # of bins\n",
    "        #bin_width = 5\n",
    "        sum_flag = False\n",
    "        pos_bin = run_binning(pos, bin_width, sum_flag)\n",
    "        print (\"pos bin: \", pos_bin.shape)\n",
    "\n",
    "        #\n",
    "        pos_tracks.append(pos_bin)\n",
    "\n",
    "        # add locations of the belt realtive\n",
    "        temp = np.arange(idx_ctr,idx_ctr+n_timesteps,1)\n",
    "        idx_tracks.append(temp)\n",
    "    \n",
    "        idx_ctr+=n_timesteps\n",
    "        \n",
    "    return pos_tracks, idx_tracks\n",
    "\n",
    "def run_binning(data, bin_size=7, sum_flag=True):\n",
    "    \n",
    "    # split data into bins\n",
    "    idx = np.arange(0, data.shape[0], bin_size)\n",
    "    d2 = np.array_split(data, idx[1:])\n",
    "    \n",
    "    # sum on time axis; drop last value\n",
    "    if sum_flag:\n",
    "        d3 = np.array(d2[:-1]).sum(1)\n",
    "    else:\n",
    "        d3 = np.median(np.array(d2[:-1]), axis=1)\n",
    "    \n",
    "    print (\"   Data binned using \", bin_size, \" frame bins, final size:  \", d3.shape)\n",
    "\n",
    "    #    \n",
    "    return d3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Data binned using  1  frame bins, final size:   (37159,)\n",
      "pos bin:  (37159,)\n",
      "   Data binned using  1  frame bins, final size:   (18579,)\n",
      "pos bin:  (18579,)\n",
      "   Data binned using  1  frame bins, final size:   (37159,)\n",
      "pos bin:  (37159,)\n",
      "loading:  0 0\n",
      "loading:  0 1\n",
      "loading:  0 2\n",
      "   Data binned using  1  frame bins, final size:   (37159,)\n",
      "pos bin:  (37159,)\n",
      "   Data binned using  1  frame bins, final size:   (37159,)\n",
      "pos bin:  (37159,)\n",
      "   Data binned using  1  frame bins, final size:   (18579,)\n",
      "pos bin:  (18579,)\n",
      "loading:  1 0\n",
      "loading:  1 1\n",
      "loading:  1 2\n",
      "   Data binned using  1  frame bins, final size:   (37159,)\n",
      "pos bin:  (37159,)\n",
      "   Data binned using  1  frame bins, final size:   (18579,)\n",
      "pos bin:  (18579,)\n",
      "   Data binned using  1  frame bins, final size:   (37159,)\n",
      "pos bin:  (37159,)\n",
      "loading:  2 0\n",
      "loading:  2 1\n",
      "loading:  2 2\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "#######################################\n",
    "###### 2D/3D GRAPHICAL PLOTS ###########\n",
    "########################################\n",
    "#\n",
    "from tqdm import trange\n",
    "\n",
    "#  \n",
    "fname_tracks, fnames_ca, segment_order = reload_names()\n",
    "\n",
    "#\n",
    "len_seg_cm = 1       # discretize belt position into 6 ~equal sections\n",
    "triage_value = 0.25  # remove xx% most outlier states\n",
    "bin_width = 1        # population vector binning\n",
    "sample_rate = 30\n",
    "randomize = False\n",
    "\n",
    "#\n",
    "experiment_ids = [0,1,2]\n",
    "\n",
    "#experiment_ids = [0]\n",
    "session_ids = [0,1,2]\n",
    "\n",
    "#\n",
    "for experiment_id in experiment_ids:\n",
    "    fname_tracks1 = fname_tracks[experiment_id]\n",
    "    fname_ca1 = fnames_ca[experiment_id]\n",
    "    segment_order1 = segment_order[experiment_id]\n",
    "\n",
    "    #\n",
    "    pos_tracks, idx_tracks = load_tracks(fname_tracks1, bin_width)\n",
    "\n",
    "    # \n",
    "    for session_id in session_ids:\n",
    "     \n",
    "        print (\"loading: \", experiment_id, session_id)\n",
    "\n",
    "        #\n",
    "        data_ca = np.load(fname_ca1)\n",
    "        dimensionality = data_ca.shape[1]\n",
    "\n",
    "        #\n",
    "        root_dir = '/home/cat/'\n",
    "        fname_base = os.path.join(root_dir, \n",
    "                                  #experiment_ids[experiment_id],\n",
    "                                  os.path.split(fname_tracks1[session_id])[1].replace('.mat','_session_'+str(session_id)))\n",
    "                                                                                    \n",
    "        #\n",
    "        np.save(fname_base+ '_ca_data.npy', data_ca[:,idx_tracks[session_id]])\n",
    "        np.save(fname_base+ '_pos_track.npy', pos_tracks[session_id])\n",
    "        np.save(fname_base+ '_idx_track.npy', idx_tracks[session_id])\n",
    "                \n",
    "\n",
    "\n",
    "print (\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "donato",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
